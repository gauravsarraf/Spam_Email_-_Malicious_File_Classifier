{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "import os.path\n",
    "\n",
    "def words_generator(fileobj):\n",
    "        for line in fileobj:\n",
    "            for word in line.split():\n",
    "                yield word\n",
    "                \n",
    "def generate_freq_dictionaries(root_dir):\n",
    "        word_count_dict={}\n",
    "        file_dict = {}\n",
    "        emails_dirs = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]    \n",
    "        for emails_dir in emails_dirs:\n",
    "            dirs = [os.path.join(emails_dir,f) for f in os.listdir(emails_dir)]\n",
    "            for d in dirs:\n",
    "                emails = [os.path.join(d,f) for f in os.listdir(d)]            \n",
    "                for mail in emails:\n",
    "                    file_name = mail.rsplit('/', 1)[-1]\n",
    "                    file_dict[file_name] = {}\n",
    "                    # if email is spam, assign spam label\n",
    "                    if mail.split(\".\")[-1] == 'spam':\n",
    "                        file_dict[file_name][\"is_spam\"] = 1 # spam\n",
    "                    else:\n",
    "                        file_dict[file_name][\"is_spam\"] = 0 # ham                    \n",
    "                    f = open(mail,\"r\")\n",
    "                    words = words_generator(f)\n",
    "                    for word in words:\n",
    "                        # if word is not an alpha numeric, don't include it\n",
    "                        if word.isalpha()==False:\n",
    "                            continue                       \n",
    "                        if word not in word_count_dict:\n",
    "                              word_count_dict[word] = 0\n",
    "                        word_count_dict[word]+= 1                      \n",
    "                        if word not in file_dict[file_name]:\n",
    "                            file_dict[file_name][word] = 0\n",
    "                        file_dict[file_name][word]+=1\n",
    "        return word_count_dict,file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    " def find_most_frequent_words(word_count_dict):\n",
    "        df = pd.DataFrame(word_count_dict.items(), columns=['word', 'total_freq'])\n",
    "        df = df.sort(['total_freq'],ascending=False).head(n=3000)\n",
    "        return df['word'].tolist(), df['total_freq'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq(word,freq_dict):\n",
    "        if word in freq_dict:\n",
    "            return freq_dict[word]\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\sarra\\\\Downloads\\\\RESEARCH\\\\SpamFiltering-master\\\\SpamFiltering-master\\\\enronEmailData\\\\enron1\\\\enron1\\\\ham'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-6da3fffc5ced>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0memail_data_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"C:\\\\Users\\\\sarra\\\\Downloads\\\\RESEARCH\\\\SpamFiltering-master\\\\SpamFiltering-master\\\\enronEmailData\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mword_count_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_freq_dictionaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memail_data_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfreq_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfrequencies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_most_frequent_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_count_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-a97e9096e80c>\u001b[0m in \u001b[0;36mgenerate_freq_dictionaries\u001b[1;34m(root_dir)\u001b[0m\n\u001b[0;32m     27\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                         \u001b[0mfile_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"is_spam\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;31m# ham\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmail\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m                     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwords_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\sarra\\\\Downloads\\\\RESEARCH\\\\SpamFiltering-master\\\\SpamFiltering-master\\\\enronEmailData\\\\enron1\\\\enron1\\\\ham'"
     ]
    }
   ],
   "source": [
    "email_data_dir = \"C:\\\\Users\\\\sarra\\\\Downloads\\\\RESEARCH\\\\SpamFiltering-master\\\\SpamFiltering-master\\\\enronEmailData\"\n",
    "word_count_dict,file_dict = generate_freq_dictionaries(email_data_dir)\n",
    "freq_words,frequencies = find_most_frequent_words(word_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-aa1dd9682894>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mchunks_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# create chunks of file dictionary data and extract features preocessing each chunk iteratively\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchunks_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfreq_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'file_dict' is not defined"
     ]
    }
   ],
   "source": [
    "file_name = \"C:\\\\Users\\\\sarra\\\\Downloads\\\\RESEARCH\\\\SpamFiltering-master\\\\SpamFiltering-master\\\\features.csv\"\n",
    "\n",
    "def extract_features(file_dict,freq_words,file_name): \n",
    "        features_df = pd.DataFrame(file_dict.items(), columns=['file_name', 'freq_values'])\n",
    "        features_df['is_spam'] = features_df['freq_values'].apply(lambda x: x.get('is_spam'))\n",
    "        for word in freq_words:\n",
    "                features_df[word] = features_df['freq_values'].apply(lambda freq_dict: get_freq(word,freq_dict))\n",
    "        columns = list(features_df.columns.values)\n",
    "        columns.remove('freq_values')\n",
    "        if os.path.isfile(file_name):\n",
    "            with open(fname, 'a') as f:\n",
    "                features_df.to_csv(f, columns =columns, header=False)\n",
    "        else:\n",
    "            features_df.to_csv(file_name, columns = columns,header=columns, index=None,sep='\\t')\n",
    "        del features_df\n",
    "        \n",
    "def chunks_generator(data, SIZE):\n",
    "        it = iter(data)\n",
    "        for i in xrange(0, len(data), SIZE):\n",
    "            yield {k:data[k] for k in islice(it, SIZE)}\n",
    "\n",
    "chunks_list = []\n",
    "    # create chunks of file dictionary data and extract features preocessing each chunk iteratively\n",
    "for item in chunks_generator(file_dict, 30):\n",
    "    extract_features(item,freq_words,file_name)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
