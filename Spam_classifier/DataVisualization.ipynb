{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def words_generator(fileobj):\n",
    "    for line in fileobj:\n",
    "        for word in line.split():\n",
    "            yield word\n",
    "\n",
    "def make_Dictionary(root_dir):\n",
    "    word_count_dict={}\n",
    "    file_dict = {}\n",
    "    emails_dirs = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]    \n",
    "    for emails_dir in emails_dirs:\n",
    "        dirs = [os.path.join(emails_dir,f) for f in os.listdir(emails_dir)]\n",
    "        for d in dirs:\n",
    "            emails = [os.path.join(d,f) for f in os.listdir(d)]\n",
    "            \n",
    "            for mail in emails:\n",
    "                file_name = mail.rsplit('/', 1)[-1]\n",
    "                #file_name = file_name.replace('.','')\n",
    "                file_dict[file_name] = {}\n",
    "                if mail.split(\".\")[-2] == 'spam':\n",
    "                    file_dict[file_name][\"is_spam\"] = 1 #spam\n",
    "                else:\n",
    "                    file_dict[file_name][\"is_spam\"] = 0 #ham\n",
    "                    \n",
    "                f = open(mail,\"r\")\n",
    "                words = words_generator(f)\n",
    "                for word in words:\n",
    "                    if word.isalpha()==False:\n",
    "                        continue\n",
    "                        \n",
    "                    if word not in word_count_dict:\n",
    "                          word_count_dict[word] = 0\n",
    "                    word_count_dict[word]+= 1  \n",
    "                    \n",
    "                    if word not in file_dict[file_name]:\n",
    "                        file_dict[file_name][word] = 0\n",
    "                    file_dict[file_name][word]+=1\n",
    "                    \n",
    "    return word_count_dict,file_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def find_most_frequent_words(word_count_dict):\n",
    "        #word_freq_dict = {}\n",
    "        df = pd.DataFrame(word_count_dict.items(), columns=['word', 'total_freq'])\n",
    "        #df['total_freq'] = df['freq_values'].apply(lambda x: x.get('total'))\n",
    "        print len(df)\n",
    "        df = df.sort(['total_freq'],ascending=False).head(n=3000)\n",
    "        print df\n",
    "        return df['word'].tolist(), df['total_freq'].tolist()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_freq(word,freq_dict):\n",
    "    if word in freq_dict:\n",
    "        return freq_dict[word]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "fname = \"/home/datascience/Desktop/SpamFiltering/features.csv\"\n",
    "\n",
    "def extract_features(file_dict,freq_words): \n",
    "    features_df = pd.DataFrame(file_dict.items(), columns=['file_name', 'freq_values'])\n",
    "    features_df['is_spam'] = features_df['freq_values'].apply(lambda x: x.get('is_spam'))\n",
    "    for word in freq_words:\n",
    "            features_df[word] = features_df['freq_values'].apply(lambda freq_dict: get_freq(word,freq_dict))\n",
    "    columns = list(features_df.columns.values)\n",
    "    columns.remove('freq_values')\n",
    "    if os.path.isfile(fname):\n",
    "        with open(fname, 'a') as f:\n",
    "            features_df.to_csv(f, columns =columns, header=False)\n",
    "    else:\n",
    "        features_df.to_csv(fname, columns = columns,header=columns, index=None,sep='\\t')\n",
    "    del features_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main_dir = \"/home/datascience/Desktop/SpamFiltering/enronEmailData\"\n",
    "\n",
    "word_count_dict,file_dict = make_Dictionary(main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142102\n",
      "                   word  total_freq\n",
      "93424               the      290811\n",
      "83497                to      213040\n",
      "103220              and      157512\n",
      "32889                of      148472\n",
      "59719                 a      118080\n",
      "27066                in      106598\n",
      "89108               for       84446\n",
      "59421               you       82098\n",
      "27053                is       71546\n",
      "56432              this       63862\n",
      "113512            enron       60909\n",
      "32881                on       59530\n",
      "130087             that       56864\n",
      "96769                 i       56495\n",
      "72360                 s       52551\n",
      "2109               with       47625\n",
      "74265              your       47450\n",
      "91345                be       47004\n",
      "101138               we       43462\n",
      "19631                as       40274\n",
      "100337             from       39553\n",
      "12607              have       39035\n",
      "27056                it       38605\n",
      "70263              will       38392\n",
      "132367              are       37213\n",
      "25596               ect       35346\n",
      "56500                or       34621\n",
      "119100               at       33080\n",
      "91370                by       31405\n",
      "76389               not       29505\n",
      "...                 ...         ...\n",
      "49031              rank         276\n",
      "74226           realize         276\n",
      "71112          bradford         276\n",
      "71632              roll         276\n",
      "109209             palo         276\n",
      "141990            fired         276\n",
      "120807     subsidiaries         275\n",
      "32378               hub         275\n",
      "93081          strength         275\n",
      "58919      professionai         275\n",
      "106505         lawsuits         275\n",
      "101156        discounts         275\n",
      "137290             lake         275\n",
      "19632                ar         275\n",
      "116640           topics         275\n",
      "109278            cisco         275\n",
      "82364              task         275\n",
      "67140          anderson         274\n",
      "8744        marketplace         274\n",
      "39988             beach         274\n",
      "51533           georgia         274\n",
      "138300        confident         274\n",
      "24427               asp         273\n",
      "21710          alliance         273\n",
      "107838  representatives         273\n",
      "15884           dealers         273\n",
      "105836     capabilities         273\n",
      "88962          eastrans         273\n",
      "32887                oh         273\n",
      "82448         addressed         272\n",
      "\n",
      "[3000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "freq_words,frequencies = find_most_frequent_words(word_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "freq1 = frequencies[100:]\n",
    "plt.plot(frequencies,label=\"frequency\")\n",
    "plt.xlabel('word_index', fontsize=16)\n",
    "plt.ylabel('frequency', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def chunks(data, SIZE):\n",
    "    it = iter(data)\n",
    "    for i in xrange(0, len(data), SIZE):\n",
    "        yield {k:data[k] for k in islice(it, SIZE)}\n",
    "        \n",
    "chunks_list = []\n",
    "for item in chunks(file_dict, 30):\n",
    "    extract_features(item,freq_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1124"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
